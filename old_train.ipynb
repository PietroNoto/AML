{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip custom_hopper.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pietro/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gym\n",
    "from stable_baselines3 import SAC\n",
    "from env.custom_hopper import *\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.sac.policies import MlpPolicy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "#from optimize_hyperparam import optimize\n",
    "from os.path import exists\n",
    "#from statistics import mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Register and train source domain environment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Monitor(gym.make(\"CustomHopper-source-v0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(\"SAC_source_env.zip\"):\n",
    "    model = SAC.load(\"SAC_source_env\")\n",
    "else:\n",
    "    model = SAC(MlpPolicy, env, verbose=1)\n",
    "    model.learn(total_timesteps = 50000, log_interval = 10)\n",
    "    model.save(\"SAC_source_env\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test source environment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = Monitor(gym.make('CustomHopper-source-v0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval = 50\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes = n_eval, deterministic = True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Register and train target domain environment</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CustomHopper-target-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.4     |\n",
      "|    ep_rew_mean     | 43.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 1718     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.7    |\n",
      "|    critic_loss     | 2.43     |\n",
      "|    ent_coef        | 0.623    |\n",
      "|    ent_coef_loss   | -2.14    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1617     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 64.9     |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 162      |\n",
      "|    total_timesteps | 6487     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -60.1    |\n",
      "|    critic_loss     | 11.4     |\n",
      "|    ent_coef        | 0.173    |\n",
      "|    ent_coef_loss   | -4.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6386     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 150      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 13049    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 7.59     |\n",
      "|    ent_coef        | 0.0816   |\n",
      "|    ent_coef_loss   | 0.363    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12948    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 137      |\n",
      "|    ep_rew_mean     | 299      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 400      |\n",
      "|    total_timesteps | 20219    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 60.1     |\n",
      "|    ent_coef        | 0.111    |\n",
      "|    ent_coef_loss   | -0.541   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20118    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 143      |\n",
      "|    ep_rew_mean     | 321      |\n",
      "| time/              |          |\n",
      "|    episodes        | 250      |\n",
      "|    fps             | 55       |\n",
      "|    time_elapsed    | 494      |\n",
      "|    total_timesteps | 27388    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -136     |\n",
      "|    critic_loss     | 5.74     |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | -0.447   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27287    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 149      |\n",
      "|    ep_rew_mean     | 332      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 57       |\n",
      "|    time_elapsed    | 613      |\n",
      "|    total_timesteps | 35124    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -123     |\n",
      "|    critic_loss     | 5.09     |\n",
      "|    ent_coef        | 0.09     |\n",
      "|    ent_coef_loss   | -0.197   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35023    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 171      |\n",
      "|    ep_rew_mean     | 348      |\n",
      "| time/              |          |\n",
      "|    episodes        | 350      |\n",
      "|    fps             | 58       |\n",
      "|    time_elapsed    | 758      |\n",
      "|    total_timesteps | 44440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 5.18     |\n",
      "|    ent_coef        | 0.0659   |\n",
      "|    ent_coef_loss   | 0.104    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 44339    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "if exists(\"SAC_target_env.zip\"):\n",
    "    model = SAC.load(\"SAC_target_env\")\n",
    "    print(f\"Learning rate: target domain: {model.learning_rate}\")\n",
    "else:\n",
    "    model = SAC(MlpPolicy, env, verbose=1)\n",
    "    model.learn(total_timesteps = 50000, log_interval = 50)\n",
    "    model.save(\"SAC_target_env\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hyperparameter optimization for source domain</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 optimize_hyperparam.py --algo sac --env CustomHopper-source-v0 -n 50000 --n-trials 10 -optimize --n-jobs 8 --conf-file standard_config.yml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train source environment using optimized hyperparameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(\"SAaaC_source_env_opt.zip\"):\n",
    "    model_opt = SAC.load(\"SAC_source_env_opt\")\n",
    "else:\n",
    "    gamma = 0.999               \n",
    "    lr = 0.003 \n",
    "    batch_size = 128          \n",
    "    buff_size = 10000       \n",
    "    learning_starts = 10000        \n",
    "    train_freq = 10\n",
    "    tau = 0.01\n",
    "    log_std_init = -3.064007572504874\n",
    "    model_opt = SAC(MlpPolicy, env, verbose=1, gamma=gamma, learning_rate=lr, batch_size=batch_size, buffer_size=buff_size, learning_starts=learning_starts, train_freq=train_freq, tau=tau)\n",
    "    model_opt.learn(total_timesteps = 50000, log_interval = 50)\n",
    "    model.save(\"SAC_source_env_opt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test source environment using optimized hyperparameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval = 50\n",
    "mean_reward, std_reward = evaluate_policy(model_opt, eval_env, n_eval_episodes = n_eval, deterministic = True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hyperparameter optimization for target domain</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 optimize_hyperparam.py --algo sac --env CustomHopper-target-v0 -n 500 -optimize --n-jobs 4 --conf-file standard_config.yml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
